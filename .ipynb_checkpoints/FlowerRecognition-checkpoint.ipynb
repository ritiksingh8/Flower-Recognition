{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from PIL import Image\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "\n",
    "from keras.callbacks import Callback\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.listdir(\"flowers-recognition/flowers/flowers\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'flowers-recognition/flowers/flowers'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_dir = os.path.dirname(\".\")\n",
    "training_set_path = os.path.join(script_dir, 'flowers-recognition/flowers/flowers')\n",
    "test_set_path = os.path.join(script_dir, 'flowers-recognition/flowers/flowers')\n",
    "script_dir\n",
    "training_set_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ritik\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\")`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(256,256,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),dim_ordering=\"th\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=1e-3, decay=1e-6), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_data_generator = ImageDataGenerator(rescale=1. / 255,\n",
    "                                           shear_range=0.2,\n",
    "                                           zoom_range=0.2,\n",
    "                                           horizontal_flip=True)\n",
    "test_data_generator = ImageDataGenerator(rescale=1. / 255,\n",
    "                                           validation_split=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4323 images belonging to 5 classes.\n",
      "Found 1424 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "input_size = (256,256)\n",
    "training_set = train_data_generator.flow_from_directory(training_set_path,\n",
    "                                                 target_size=input_size,\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 subset=\"training\",\n",
    "                                                 class_mode='categorical')\n",
    "\n",
    "test_set = test_data_generator.flow_from_directory(test_set_path,\n",
    "                                            target_size=input_size,\n",
    "                                            batch_size=batch_size,\n",
    "                                            subset=\"validation\",\n",
    "                                            class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_19 (Conv2D)           (None, 254, 254, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 254, 127, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 252, 125, 32)      4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 126, 62, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 124, 60, 64)       18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 62, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 119040)            0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 64)                7618624   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 7,642,981\n",
      "Trainable params: 7,642,981\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "32/31 [==============================] - 103s 3s/step - loss: 1.8322 - accuracy: 0.2623 - val_loss: 1.4529 - val_accuracy: 0.2891\n",
      "Epoch 2/30\n",
      "32/31 [==============================] - 61s 2s/step - loss: 1.4379 - accuracy: 0.3584 - val_loss: 1.3510 - val_accuracy: 0.4688\n",
      "Epoch 3/30\n",
      " 1/31 [..............................] - ETA: 50s - loss: 1.3980 - accuracy: 0.3438"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ritik\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\callbacks\\callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (2.075699). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/31 [==============================] - 57s 2s/step - loss: 1.3324 - accuracy: 0.4170 - val_loss: 1.3642 - val_accuracy: 0.3594\n",
      "Epoch 4/30\n",
      "32/31 [==============================] - 53s 2s/step - loss: 1.2998 - accuracy: 0.4414 - val_loss: 1.3441 - val_accuracy: 0.4531\n",
      "Epoch 5/30\n",
      "32/31 [==============================] - 51s 2s/step - loss: 1.3403 - accuracy: 0.4583 - val_loss: 1.4532 - val_accuracy: 0.4297\n",
      "Epoch 6/30\n",
      "32/31 [==============================] - 52s 2s/step - loss: 1.2866 - accuracy: 0.4590 - val_loss: 1.1180 - val_accuracy: 0.5234\n",
      "Epoch 7/30\n",
      "32/31 [==============================] - 53s 2s/step - loss: 1.2074 - accuracy: 0.5010 - val_loss: 1.0698 - val_accuracy: 0.5156\n",
      "Epoch 8/30\n",
      "32/31 [==============================] - 54s 2s/step - loss: 1.2247 - accuracy: 0.4863 - val_loss: 1.1278 - val_accuracy: 0.4922\n",
      "Epoch 9/30\n",
      "32/31 [==============================] - 54s 2s/step - loss: 1.1459 - accuracy: 0.5352 - val_loss: 0.8662 - val_accuracy: 0.6328\n",
      "Epoch 10/30\n",
      "32/31 [==============================] - 56s 2s/step - loss: 1.1439 - accuracy: 0.5576 - val_loss: 1.2993 - val_accuracy: 0.5938\n",
      "Epoch 11/30\n",
      "32/31 [==============================] - 55s 2s/step - loss: 1.1646 - accuracy: 0.5342 - val_loss: 0.9790 - val_accuracy: 0.5234\n",
      "Epoch 12/30\n",
      "32/31 [==============================] - 55s 2s/step - loss: 1.1014 - accuracy: 0.5469 - val_loss: 1.0240 - val_accuracy: 0.6161\n",
      "Epoch 13/30\n",
      "32/31 [==============================] - 54s 2s/step - loss: 1.0889 - accuracy: 0.5839 - val_loss: 1.1183 - val_accuracy: 0.6094\n",
      "Epoch 14/30\n",
      "32/31 [==============================] - 55s 2s/step - loss: 1.0675 - accuracy: 0.5840 - val_loss: 0.9786 - val_accuracy: 0.6641\n",
      "Epoch 15/30\n",
      "32/31 [==============================] - 55s 2s/step - loss: 1.0705 - accuracy: 0.5723 - val_loss: 0.9387 - val_accuracy: 0.6953\n",
      "Epoch 16/30\n",
      "32/31 [==============================] - 55s 2s/step - loss: 1.0979 - accuracy: 0.5654 - val_loss: 1.1521 - val_accuracy: 0.5625\n",
      "Epoch 17/30\n",
      "32/31 [==============================] - 54s 2s/step - loss: 1.0707 - accuracy: 0.5960 - val_loss: 0.9554 - val_accuracy: 0.6094\n",
      "Epoch 18/30\n",
      "32/31 [==============================] - 55s 2s/step - loss: 1.0399 - accuracy: 0.6084 - val_loss: 0.8648 - val_accuracy: 0.7031\n",
      "Epoch 19/30\n",
      "32/31 [==============================] - 54s 2s/step - loss: 0.9777 - accuracy: 0.6221 - val_loss: 0.9661 - val_accuracy: 0.7109\n",
      "Epoch 20/30\n",
      "32/31 [==============================] - 54s 2s/step - loss: 0.9969 - accuracy: 0.6302 - val_loss: 0.6074 - val_accuracy: 0.6719\n",
      "Epoch 21/30\n",
      "32/31 [==============================] - 55s 2s/step - loss: 1.0038 - accuracy: 0.6113 - val_loss: 0.7988 - val_accuracy: 0.7109\n",
      "Epoch 22/30\n",
      "32/31 [==============================] - 55s 2s/step - loss: 0.9434 - accuracy: 0.6357 - val_loss: 0.8345 - val_accuracy: 0.6562\n",
      "Epoch 23/30\n",
      "32/31 [==============================] - 53s 2s/step - loss: 0.9472 - accuracy: 0.6377 - val_loss: 0.8129 - val_accuracy: 0.6429\n",
      "Epoch 24/30\n",
      "32/31 [==============================] - 53s 2s/step - loss: 0.9783 - accuracy: 0.6328 - val_loss: 0.9958 - val_accuracy: 0.6406\n",
      "Epoch 25/30\n",
      "32/31 [==============================] - 52s 2s/step - loss: 0.9102 - accuracy: 0.6573 - val_loss: 0.6499 - val_accuracy: 0.6797\n",
      "Epoch 26/30\n",
      "32/31 [==============================] - 54s 2s/step - loss: 0.9783 - accuracy: 0.6230 - val_loss: 0.6829 - val_accuracy: 0.6875\n",
      "Epoch 27/30\n",
      "32/31 [==============================] - 52s 2s/step - loss: 0.9016 - accuracy: 0.6302 - val_loss: 1.0961 - val_accuracy: 0.6484\n",
      "Epoch 28/30\n",
      "32/31 [==============================] - 53s 2s/step - loss: 0.8964 - accuracy: 0.6611 - val_loss: 0.6256 - val_accuracy: 0.6875\n",
      "Epoch 29/30\n",
      "32/31 [==============================] - 54s 2s/step - loss: 0.9232 - accuracy: 0.6514 - val_loss: 0.8045 - val_accuracy: 0.7344\n",
      "Epoch 30/30\n",
      "32/31 [==============================] - 53s 2s/step - loss: 0.8559 - accuracy: 0.6794 - val_loss: 0.7189 - val_accuracy: 0.6797\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(training_set,\n",
    "                         steps_per_epoch=1000/batch_size,\n",
    "                         epochs=30,\n",
    "                         validation_data=test_set,\n",
    "                         validation_steps=100/batch_size,\n",
    "                         workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
